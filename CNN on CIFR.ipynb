{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3555,
     "status": "ok",
     "timestamp": 1571800558932,
     "user": {
      "displayName": "sandeep Burra",
      "photoUrl": "",
      "userId": "00094485018250843945"
     },
     "user_tz": -330
    },
    "id": "wVIx_KIigxPV",
    "outputId": "09589814-fb74-4b9b-e97e-57ffc672e5d7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "import tensorflow.python.keras\n",
    "from tensorflow.python.keras import models, layers\n",
    "from tensorflow.python.keras.layers import SeparableConv2D, DepthwiseConv2D\n",
    "from tensorflow.python.keras.models import Model, load_model\n",
    "from tensorflow.python.keras.layers import BatchNormalization, Activation, Flatten\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dsO_yGxcg5D8"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "l = 40\n",
    "compression = 0.55\n",
    "dropout_rate = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5337,
     "status": "ok",
     "timestamp": 1571800644940,
     "user": {
      "displayName": "sandeep Burra",
      "photoUrl": "",
      "userId": "00094485018250843945"
     },
     "user_tz": -330
    },
    "id": "mB7o3zu1g6eT",
    "outputId": "65d8e8db-3692-4c70-8a15-f6a324bb1d84"
   },
   "outputs": [],
   "source": [
    "# Load CIFAR10 Data\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "img_height, img_width, channel = X_train.shape[1],X_train.shape[2],X_train.shape[3]\n",
    "\n",
    "# convert to one hot encoing \n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 784,
     "status": "ok",
     "timestamp": 1571800647028,
     "user": {
      "displayName": "sandeep Burra",
      "photoUrl": "",
      "userId": "00094485018250843945"
     },
     "user_tz": -330
    },
    "id": "287_ZgFXB-ZX",
    "outputId": "3ba0af91-d1ea-40ce-df9b-084ef533fb89"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 551,
     "status": "ok",
     "timestamp": 1571800648227,
     "user": {
      "displayName": "sandeep Burra",
      "photoUrl": "",
      "userId": "00094485018250843945"
     },
     "user_tz": -330
    },
    "id": "yg8P3ve8B-Zb",
    "outputId": "affe5a55-9f01-4315-b656-4c3fc1bcfaec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0U-KL2phnPRX"
   },
   "outputs": [],
   "source": [
    "X_train_mean = np.mean(X_train, axis=(0,1,2))\n",
    "X_train_std = np.std(X_train, axis=(0,1,2))\n",
    "X_train = (X_train - X_train_mean) / X_train_std\n",
    "X_test = (X_test - X_train_mean) / X_train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8ggyKUbYm9Zy"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Dense Block\n",
    "def denseblock(input, num_filter = 12, dropout_rate = 0.2):\n",
    "    global compression\n",
    "    temp = input\n",
    "    for _ in range(l): \n",
    "        BatchNorm = layers.BatchNormalization()(temp)\n",
    "        relu = layers.Activation('relu')(BatchNorm)\n",
    "        Conv2D_3_3 = layers.SeparableConv2D(int(num_filter*compression), (5,5), use_bias=False ,padding='same')(relu)\n",
    "        if dropout_rate>0:\n",
    "            Conv2D_3_3 = layers.Dropout(dropout_rate)(Conv2D_3_3)\n",
    "        concat = layers.Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
    "        \n",
    "        temp = concat\n",
    "        \n",
    "    return temp\n",
    "\n",
    "## transition Blosck\n",
    "def transition(input, num_filter = 12, dropout_rate = 0.2):\n",
    "    global compression\n",
    "    BatchNorm = layers.BatchNormalization()(input)\n",
    "    relu = layers.Activation('relu')(BatchNorm)\n",
    "    Conv2D_BottleNeck = layers.SeparableConv2D(int(num_filter*compression), (5,5), use_bias=False,padding='same')(relu)\n",
    "    if dropout_rate>0:\n",
    "         Conv2D_BottleNeck = layers.Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
    "    avg = layers.AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
    "    return avg\n",
    "\n",
    "#output layer\n",
    "def output_layer(input):\n",
    "    global compression\n",
    "    BatchNorm = layers.BatchNormalization()(input)\n",
    "    relu = layers.Activation('relu')(BatchNorm)\n",
    "    AvgPooling = layers.AveragePooling2D(pool_size=(4,4))(relu)\n",
    "    #flat = layers.Flatten()(AvgPooling)\n",
    "    output = layers.SeparableConv2D(num_classes, (5,5), use_bias=False,padding='same', activation='softmax')(AvgPooling)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V2ZiBEeom9aG"
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "K.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g845JPMCm9aS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\addu\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "num_filter = 126\n",
    "\n",
    "dropout_rate = 0\n",
    "l = 7\n",
    "\n",
    "input = layers.Input(shape=(img_height, img_width, channel,))\n",
    "First_Conv2D = layers.SeparableConv2D(num_filter, (5,5), use_bias=False, padding='same')(input)\n",
    "\n",
    "First_Block = denseblock(First_Conv2D, num_filter, dropout_rate)\n",
    "First_Transition = transition(First_Block, num_filter, dropout_rate)\n",
    "\n",
    "Second_Block = denseblock(First_Transition, num_filter, dropout_rate)\n",
    "Second_Transition = transition(Second_Block, num_filter, dropout_rate)\n",
    "\n",
    "Third_Block = denseblock(Second_Transition, num_filter, dropout_rate)\n",
    "Third_Transition = transition(Third_Block, num_filter, dropout_rate)\n",
    "\n",
    "Last_Block = denseblock(Third_Transition,  num_filter, dropout_rate)\n",
    "output = output_layer(Last_Block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2625,
     "status": "ok",
     "timestamp": 1571804876146,
     "user": {
      "displayName": "sandeep Burra",
      "photoUrl": "",
      "userId": "00094485018250843945"
     },
     "user_tz": -330
    },
    "id": "k0bjetnMnSb3",
    "outputId": "70a87f94-7cc2-4559-c2cd-1b58d61ed82c",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d (SeparableConv (None, 32, 32, 126)  453         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 126)  504         separable_conv2d[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32, 32, 126)  0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_1 (SeparableCo (None, 32, 32, 69)   11844       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32, 32, 195)  0           separable_conv2d[0][0]           \n",
      "                                                                 separable_conv2d_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 195)  780         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 195)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2 (SeparableCo (None, 32, 32, 69)   18330       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 264)  0           concatenate[0][0]                \n",
      "                                                                 separable_conv2d_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 264)  1056        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 264)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_3 (SeparableCo (None, 32, 32, 69)   24816       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 333)  0           concatenate_1[0][0]              \n",
      "                                                                 separable_conv2d_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 333)  1332        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 333)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_4 (SeparableCo (None, 32, 32, 69)   31302       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 32, 32, 402)  0           concatenate_2[0][0]              \n",
      "                                                                 separable_conv2d_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 402)  1608        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 402)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_5 (SeparableCo (None, 32, 32, 69)   37788       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32, 32, 471)  0           concatenate_3[0][0]              \n",
      "                                                                 separable_conv2d_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 471)  1884        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 471)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_6 (SeparableCo (None, 32, 32, 69)   44274       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 32, 32, 540)  0           concatenate_4[0][0]              \n",
      "                                                                 separable_conv2d_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 540)  2160        concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 540)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_7 (SeparableCo (None, 32, 32, 69)   50760       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 32, 32, 609)  0           concatenate_5[0][0]              \n",
      "                                                                 separable_conv2d_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 609)  2436        concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 609)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_8 (SeparableCo (None, 32, 32, 69)   57246       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 16, 16, 69)   0           separable_conv2d_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 69)   276         average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 69)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_9 (SeparableCo (None, 16, 16, 69)   6486        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 16, 16, 138)  0           average_pooling2d[0][0]          \n",
      "                                                                 separable_conv2d_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 138)  552         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 138)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_10 (SeparableC (None, 16, 16, 69)   12972       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 16, 16, 207)  0           concatenate_7[0][0]              \n",
      "                                                                 separable_conv2d_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 207)  828         concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 207)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_11 (SeparableC (None, 16, 16, 69)   19458       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 16, 16, 276)  0           concatenate_8[0][0]              \n",
      "                                                                 separable_conv2d_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 276)  1104        concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 276)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_12 (SeparableC (None, 16, 16, 69)   25944       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 16, 16, 345)  0           concatenate_9[0][0]              \n",
      "                                                                 separable_conv2d_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 345)  1380        concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 345)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_13 (SeparableC (None, 16, 16, 69)   32430       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 16, 16, 414)  0           concatenate_10[0][0]             \n",
      "                                                                 separable_conv2d_13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 414)  1656        concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 414)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_14 (SeparableC (None, 16, 16, 69)   38916       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 16, 16, 483)  0           concatenate_11[0][0]             \n",
      "                                                                 separable_conv2d_14[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 483)  1932        concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 483)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_15 (SeparableC (None, 16, 16, 69)   45402       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 16, 16, 552)  0           concatenate_12[0][0]             \n",
      "                                                                 separable_conv2d_15[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 552)  2208        concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 16, 552)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_16 (SeparableC (None, 16, 16, 69)   51888       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 8, 8, 69)     0           separable_conv2d_16[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 8, 8, 69)     276         average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 8, 8, 69)     0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_17 (SeparableC (None, 8, 8, 69)     6486        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 8, 8, 138)    0           average_pooling2d_1[0][0]        \n",
      "                                                                 separable_conv2d_17[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 8, 8, 138)    552         concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 8, 8, 138)    0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_18 (SeparableC (None, 8, 8, 69)     12972       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 8, 8, 207)    0           concatenate_14[0][0]             \n",
      "                                                                 separable_conv2d_18[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 8, 8, 207)    828         concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 8, 8, 207)    0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_19 (SeparableC (None, 8, 8, 69)     19458       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 8, 8, 276)    0           concatenate_15[0][0]             \n",
      "                                                                 separable_conv2d_19[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 8, 8, 276)    1104        concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 8, 8, 276)    0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_20 (SeparableC (None, 8, 8, 69)     25944       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 8, 8, 345)    0           concatenate_16[0][0]             \n",
      "                                                                 separable_conv2d_20[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 8, 8, 345)    1380        concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 8, 8, 345)    0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_21 (SeparableC (None, 8, 8, 69)     32430       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 8, 8, 414)    0           concatenate_17[0][0]             \n",
      "                                                                 separable_conv2d_21[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 8, 8, 414)    1656        concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 8, 8, 414)    0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_22 (SeparableC (None, 8, 8, 69)     38916       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 8, 8, 483)    0           concatenate_18[0][0]             \n",
      "                                                                 separable_conv2d_22[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 8, 8, 483)    1932        concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 8, 8, 483)    0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_23 (SeparableC (None, 8, 8, 69)     45402       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 8, 8, 552)    0           concatenate_19[0][0]             \n",
      "                                                                 separable_conv2d_23[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 8, 8, 552)    2208        concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 8, 8, 552)    0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_24 (SeparableC (None, 8, 8, 69)     51888       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 4, 4, 69)     0           separable_conv2d_24[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 4, 4, 69)     276         average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 4, 4, 69)     0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_25 (SeparableC (None, 4, 4, 69)     6486        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 4, 4, 138)    0           average_pooling2d_2[0][0]        \n",
      "                                                                 separable_conv2d_25[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 4, 4, 138)    552         concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 4, 4, 138)    0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_26 (SeparableC (None, 4, 4, 69)     12972       activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 4, 4, 207)    0           concatenate_21[0][0]             \n",
      "                                                                 separable_conv2d_26[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 4, 4, 207)    828         concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 4, 4, 207)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_27 (SeparableC (None, 4, 4, 69)     19458       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 4, 4, 276)    0           concatenate_22[0][0]             \n",
      "                                                                 separable_conv2d_27[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 4, 4, 276)    1104        concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 4, 4, 276)    0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_28 (SeparableC (None, 4, 4, 69)     25944       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 4, 4, 345)    0           concatenate_23[0][0]             \n",
      "                                                                 separable_conv2d_28[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 4, 4, 345)    1380        concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 4, 4, 345)    0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_29 (SeparableC (None, 4, 4, 69)     32430       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 4, 4, 414)    0           concatenate_24[0][0]             \n",
      "                                                                 separable_conv2d_29[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 4, 4, 414)    1656        concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 4, 4, 414)    0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_30 (SeparableC (None, 4, 4, 69)     38916       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 4, 4, 483)    0           concatenate_25[0][0]             \n",
      "                                                                 separable_conv2d_30[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 4, 4, 483)    1932        concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 4, 4, 483)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_31 (SeparableC (None, 4, 4, 69)     45402       activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 4, 4, 552)    0           concatenate_26[0][0]             \n",
      "                                                                 separable_conv2d_31[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 4, 4, 552)    2208        concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 4, 4, 552)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 1, 1, 552)    0           activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_32 (SeparableC (None, 1, 1, 10)     19320       average_pooling2d_3[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 986,301\n",
      "Trainable params: 965,517\n",
      "Non-trainable params: 20,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[input], outputs=[output])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "StpOIZ7oA6cw"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.10,\n",
    "    )\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l4Z3iNkPJLoU"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, EarlyStopping,ReduceLROnPlateau, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ipb_Nt23AN82"
   },
   "outputs": [],
   "source": [
    "filepath=\"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint_1 = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, mode='max')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3ozyhOX_xSqt"
   },
   "outputs": [],
   "source": [
    "reduce_lr_1 = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                              patience=4,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ckua1H9TC2wA"
   },
   "outputs": [],
   "source": [
    "earlystopping_1 = EarlyStopping(monitor='val_loss', patience=40, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h3lFweREIKuS"
   },
   "outputs": [],
   "source": [
    "callbacks_list = [earlystopping_1,reduce_lr_1,checkpoint_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b4XOsW3ahSkL"
   },
   "outputs": [],
   "source": [
    "# determine Loss function and Optimizer\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping to match with convoultion output layer\n",
    "y_train_re = np.reshape(y_train, (50000,1,1,10))\n",
    "y_test_re = np.reshape(y_test, (10000,1,1,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1507390,
     "status": "ok",
     "timestamp": 1571644199025,
     "user": {
      "displayName": "sandeep Burra",
      "photoUrl": "",
      "userId": "00094485018250843945"
     },
     "user_tz": -330
    },
    "id": "crhGk7kEhXAz",
    "outputId": "acafc394-e8b9-49b4-aa8c-0276f608af2f",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From c:\\users\\addu\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "\n",
      "Epoch 00001: saving model to weights-improvement-01-0.49.hdf5\n",
      "781/781 - 115s - loss: 1.6273 - acc: 0.3934 - val_loss: 1.4025 - val_acc: 0.4926\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: saving model to weights-improvement-02-0.58.hdf5\n",
      "781/781 - 106s - loss: 1.1767 - acc: 0.5819 - val_loss: 1.2740 - val_acc: 0.5768\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: saving model to weights-improvement-03-0.63.hdf5\n",
      "781/781 - 109s - loss: 0.9644 - acc: 0.6608 - val_loss: 1.1408 - val_acc: 0.6313\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: saving model to weights-improvement-04-0.70.hdf5\n",
      "781/781 - 101s - loss: 0.8385 - acc: 0.7094 - val_loss: 0.9185 - val_acc: 0.6954\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: saving model to weights-improvement-05-0.71.hdf5\n",
      "781/781 - 101s - loss: 0.7522 - acc: 0.7385 - val_loss: 0.9352 - val_acc: 0.7057\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: saving model to weights-improvement-06-0.72.hdf5\n",
      "781/781 - 101s - loss: 0.6856 - acc: 0.7621 - val_loss: 0.8337 - val_acc: 0.7202\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: saving model to weights-improvement-07-0.72.hdf5\n",
      "781/781 - 101s - loss: 0.6341 - acc: 0.7794 - val_loss: 0.8199 - val_acc: 0.7237\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: saving model to weights-improvement-08-0.78.hdf5\n",
      "781/781 - 101s - loss: 0.5852 - acc: 0.7949 - val_loss: 0.6451 - val_acc: 0.7846\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: saving model to weights-improvement-09-0.80.hdf5\n",
      "781/781 - 102s - loss: 0.5534 - acc: 0.8084 - val_loss: 0.5858 - val_acc: 0.7970\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: saving model to weights-improvement-10-0.78.hdf5\n",
      "781/781 - 102s - loss: 0.5156 - acc: 0.8204 - val_loss: 0.6887 - val_acc: 0.7794\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: saving model to weights-improvement-11-0.82.hdf5\n",
      "781/781 - 101s - loss: 0.4938 - acc: 0.8286 - val_loss: 0.5578 - val_acc: 0.8189\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: saving model to weights-improvement-12-0.81.hdf5\n",
      "781/781 - 101s - loss: 0.4671 - acc: 0.8371 - val_loss: 0.5667 - val_acc: 0.8123\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: saving model to weights-improvement-13-0.83.hdf5\n",
      "781/781 - 101s - loss: 0.4413 - acc: 0.8473 - val_loss: 0.5197 - val_acc: 0.8296\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: saving model to weights-improvement-14-0.84.hdf5\n",
      "781/781 - 101s - loss: 0.4293 - acc: 0.8512 - val_loss: 0.5088 - val_acc: 0.8384\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: saving model to weights-improvement-15-0.82.hdf5\n",
      "781/781 - 101s - loss: 0.4143 - acc: 0.8549 - val_loss: 0.5425 - val_acc: 0.8236\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: saving model to weights-improvement-16-0.83.hdf5\n",
      "781/781 - 101s - loss: 0.3955 - acc: 0.8621 - val_loss: 0.5230 - val_acc: 0.8299\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: saving model to weights-improvement-17-0.84.hdf5\n",
      "781/781 - 101s - loss: 0.3767 - acc: 0.8692 - val_loss: 0.5008 - val_acc: 0.8386\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: saving model to weights-improvement-18-0.86.hdf5\n",
      "781/781 - 101s - loss: 0.3635 - acc: 0.8751 - val_loss: 0.4452 - val_acc: 0.8565\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: saving model to weights-improvement-19-0.86.hdf5\n",
      "781/781 - 101s - loss: 0.3544 - acc: 0.8776 - val_loss: 0.4156 - val_acc: 0.8602\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: saving model to weights-improvement-20-0.86.hdf5\n",
      "781/781 - 101s - loss: 0.3423 - acc: 0.8806 - val_loss: 0.4210 - val_acc: 0.8606\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: saving model to weights-improvement-21-0.86.hdf5\n",
      "781/781 - 102s - loss: 0.3282 - acc: 0.8858 - val_loss: 0.4181 - val_acc: 0.8620\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: saving model to weights-improvement-22-0.88.hdf5\n",
      "781/781 - 101s - loss: 0.3174 - acc: 0.8894 - val_loss: 0.3663 - val_acc: 0.8813\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: saving model to weights-improvement-23-0.85.hdf5\n",
      "781/781 - 101s - loss: 0.3070 - acc: 0.8928 - val_loss: 0.4768 - val_acc: 0.8516\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: saving model to weights-improvement-24-0.85.hdf5\n",
      "781/781 - 103s - loss: 0.2977 - acc: 0.8958 - val_loss: 0.4744 - val_acc: 0.8532\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: saving model to weights-improvement-25-0.84.hdf5\n",
      "781/781 - 102s - loss: 0.2871 - acc: 0.8991 - val_loss: 0.5175 - val_acc: 0.8416\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00026: saving model to weights-improvement-26-0.86.hdf5\n",
      "781/781 - 101s - loss: 0.2771 - acc: 0.9026 - val_loss: 0.4370 - val_acc: 0.8614\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: saving model to weights-improvement-27-0.90.hdf5\n",
      "781/781 - 101s - loss: 0.2141 - acc: 0.9256 - val_loss: 0.3077 - val_acc: 0.9011\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: saving model to weights-improvement-28-0.91.hdf5\n",
      "781/781 - 101s - loss: 0.1873 - acc: 0.9355 - val_loss: 0.2864 - val_acc: 0.9084\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: saving model to weights-improvement-29-0.90.hdf5\n",
      "781/781 - 101s - loss: 0.1781 - acc: 0.9388 - val_loss: 0.3104 - val_acc: 0.9029\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: saving model to weights-improvement-30-0.90.hdf5\n",
      "781/781 - 101s - loss: 0.1670 - acc: 0.9419 - val_loss: 0.3119 - val_acc: 0.9037\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: saving model to weights-improvement-31-0.91.hdf5\n",
      "781/781 - 101s - loss: 0.1624 - acc: 0.9444 - val_loss: 0.3107 - val_acc: 0.9058\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00032: saving model to weights-improvement-32-0.90.hdf5\n",
      "781/781 - 101s - loss: 0.1591 - acc: 0.9452 - val_loss: 0.3129 - val_acc: 0.9046\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: saving model to weights-improvement-33-0.91.hdf5\n",
      "781/781 - 101s - loss: 0.1508 - acc: 0.9468 - val_loss: 0.3057 - val_acc: 0.9085\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: saving model to weights-improvement-34-0.91.hdf5\n",
      "781/781 - 101s - loss: 0.1501 - acc: 0.9470 - val_loss: 0.3020 - val_acc: 0.9092\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: saving model to weights-improvement-35-0.91.hdf5\n",
      "781/781 - 101s - loss: 0.1484 - acc: 0.9489 - val_loss: 0.3024 - val_acc: 0.9091\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 00036: saving model to weights-improvement-36-0.91.hdf5\n",
      "781/781 - 101s - loss: 0.1476 - acc: 0.9494 - val_loss: 0.3028 - val_acc: 0.9081\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: saving model to weights-improvement-37-0.91.hdf5\n",
      "781/781 - 101s - loss: 0.1413 - acc: 0.9507 - val_loss: 0.3018 - val_acc: 0.9087\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: saving model to weights-improvement-38-0.91.hdf5\n",
      "781/781 - 101s - loss: 0.1489 - acc: 0.9474 - val_loss: 0.3008 - val_acc: 0.9087\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: saving model to weights-improvement-39-0.91.hdf5\n",
      "781/781 - 101s - loss: 0.1456 - acc: 0.9500 - val_loss: 0.3008 - val_acc: 0.9084\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\n",
      "Epoch 00040: saving model to weights-improvement-40-0.91.hdf5\n",
      "781/781 - 101s - loss: 0.1454 - acc: 0.9496 - val_loss: 0.3009 - val_acc: 0.9092\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 00041: saving model to weights-improvement-41-0.91.hdf5\n",
      "781/781 - 101s - loss: 0.1446 - acc: 0.9492 - val_loss: 0.3018 - val_acc: 0.9084\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 00042: saving model to weights-improvement-42-0.91.hdf5\n",
      "781/781 - 101s - loss: 0.1452 - acc: 0.9496 - val_loss: 0.3035 - val_acc: 0.9082\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 00043: saving model to weights-improvement-43-0.91.hdf5\n",
      "781/781 - 101s - loss: 0.1427 - acc: 0.9507 - val_loss: 0.3012 - val_acc: 0.9089\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "\n",
      "Epoch 00044: saving model to weights-improvement-44-0.91.hdf5\n",
      "781/781 - 101s - loss: 0.1493 - acc: 0.9487 - val_loss: 0.3034 - val_acc: 0.9083\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 00045: saving model to weights-improvement-45-0.91.hdf5\n",
      "781/781 - 101s - loss: 0.1458 - acc: 0.9482 - val_loss: 0.2996 - val_acc: 0.9092\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 00046: saving model to weights-improvement-46-0.91.hdf5\n",
      "781/781 - 101s - loss: 0.1443 - acc: 0.9492 - val_loss: 0.3015 - val_acc: 0.9089\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 00047: saving model to weights-improvement-47-0.91.hdf5\n",
      "781/781 - 101s - loss: 0.1446 - acc: 0.9501 - val_loss: 0.3008 - val_acc: 0.9090\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "\n",
      "Epoch 00048: saving model to weights-improvement-48-0.91.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 - 101s - loss: 0.1457 - acc: 0.9489 - val_loss: 0.3012 - val_acc: 0.9083\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 00049: saving model to weights-improvement-49-0.91.hdf5\n",
      "781/781 - 101s - loss: 0.1437 - acc: 0.9496 - val_loss: 0.3002 - val_acc: 0.9088\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 00050: saving model to weights-improvement-50-0.91.hdf5\n",
      "781/781 - 107s - loss: 0.1438 - acc: 0.9504 - val_loss: 0.3000 - val_acc: 0.9092\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 00051: saving model to weights-improvement-51-0.91.hdf5\n",
      "781/781 - 107s - loss: 0.1459 - acc: 0.9500 - val_loss: 0.3047 - val_acc: 0.9070\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "\n",
      "Epoch 00052: saving model to weights-improvement-52-0.91.hdf5\n",
      "781/781 - 102s - loss: 0.1446 - acc: 0.9495 - val_loss: 0.3031 - val_acc: 0.9076\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 00053: saving model to weights-improvement-53-0.91.hdf5\n",
      "781/781 - 106s - loss: 0.1439 - acc: 0.9503 - val_loss: 0.2994 - val_acc: 0.9097\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 00054: saving model to weights-improvement-54-0.91.hdf5\n",
      "781/781 - 106s - loss: 0.1446 - acc: 0.9495 - val_loss: 0.3015 - val_acc: 0.9086\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 00055: saving model to weights-improvement-55-0.91.hdf5\n",
      "781/781 - 106s - loss: 0.1461 - acc: 0.9480 - val_loss: 0.3024 - val_acc: 0.9089\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "\n",
      "Epoch 00056: saving model to weights-improvement-56-0.91.hdf5\n",
      "781/781 - 107s - loss: 0.1462 - acc: 0.9492 - val_loss: 0.3012 - val_acc: 0.9083\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 00057: saving model to weights-improvement-57-0.91.hdf5\n",
      "781/781 - 106s - loss: 0.1449 - acc: 0.9505 - val_loss: 0.3023 - val_acc: 0.9088\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 00058: saving model to weights-improvement-58-0.91.hdf5\n",
      "781/781 - 106s - loss: 0.1445 - acc: 0.9491 - val_loss: 0.3021 - val_acc: 0.9089\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 00059: saving model to weights-improvement-59-0.91.hdf5\n",
      "781/781 - 107s - loss: 0.1459 - acc: 0.9485 - val_loss: 0.3023 - val_acc: 0.9084\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "\n",
      "Epoch 00060: saving model to weights-improvement-60-0.91.hdf5\n",
      "781/781 - 107s - loss: 0.1468 - acc: 0.9489 - val_loss: 0.3016 - val_acc: 0.9091\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 00061: saving model to weights-improvement-61-0.91.hdf5\n",
      "781/781 - 107s - loss: 0.1451 - acc: 0.9490 - val_loss: 0.3023 - val_acc: 0.9081\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 00062: saving model to weights-improvement-62-0.91.hdf5\n",
      "781/781 - 106s - loss: 0.1421 - acc: 0.9502 - val_loss: 0.3008 - val_acc: 0.9085\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 00063: saving model to weights-improvement-63-0.91.hdf5\n",
      "781/781 - 106s - loss: 0.1442 - acc: 0.9498 - val_loss: 0.3014 - val_acc: 0.9088\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
      "\n",
      "Epoch 00064: saving model to weights-improvement-64-0.91.hdf5\n",
      "781/781 - 131s - loss: 0.1457 - acc: 0.9480 - val_loss: 0.3023 - val_acc: 0.9089\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 00065: saving model to weights-improvement-65-0.91.hdf5\n",
      "781/781 - 115s - loss: 0.1415 - acc: 0.9511 - val_loss: 0.3004 - val_acc: 0.9090\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 00066: saving model to weights-improvement-66-0.91.hdf5\n",
      "781/781 - 103s - loss: 0.1411 - acc: 0.9511 - val_loss: 0.3045 - val_acc: 0.9079\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 00067: saving model to weights-improvement-67-0.91.hdf5\n",
      "781/781 - 101s - loss: 0.1454 - acc: 0.9485 - val_loss: 0.3010 - val_acc: 0.9091\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 1.0000001179769417e-14.\n",
      "\n",
      "Epoch 00068: saving model to weights-improvement-68-0.91.hdf5\n",
      "781/781 - 101s - loss: 0.1433 - acc: 0.9496 - val_loss: 0.3024 - val_acc: 0.9088\n",
      "Epoch 00068: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(datagen.flow(X_train, y_train_re, batch_size=batch_size),\n",
    "                    steps_per_epoch=X_train.shape[0] // batch_size,\n",
    "                    epochs=100,\n",
    "                    verbose=2, \n",
    "                    validation_data=(X_test, y_test_re),callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZcWydmIVhZGr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 5s 549us/sample - loss: 0.3026 - acc: 0.9088\n",
      "Test loss: 0.3025546526670456\n",
      "Test accuracy: 0.9088\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "score = model.evaluate(X_test, y_test_re, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UE3lF6EH1r_L"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# Save the trained weights in to .h5 format\n",
    "model.save_weights(\"DNST_model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "* Applied DenseNet architecture on CIFR10 dataset\n",
    "* Tuned the architecture \n",
    "* Obtained a test accuracy of 90.88"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of DenseNet - cifar10.ipynb",
   "provenance": [
    {
     "file_id": "16-fwEHK6Pl9j_Kt546WNb2wx9Z_ky6W-",
     "timestamp": 1566707289180
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
